# Ollama
OLLAMA_HOST="localhost"
OLLAMA_MODEL_NAME="llama3.2:3b-instruct-q8_0"

# OpenRouter
OPENROUTER_BASE_URL="https://openrouter.ai/api/v1"
OPENROUTER_API_KEY=
OPENROUTER_MODEL_NAME="google/gemini-2.0-flash-lite-preview-02-05:free"

# LiteLLM Proxy (LLM Gateway)
LITELLM_PROXY_API_KEY=
LITELLM_PROXY_API_BASE="http://localhost:4000"

# Model name to be used through LiteLLM Proxy (LLM Gateway)
LITELLM_PROXY_MODEL_NAME="llama3.2:3b-instruct-q8_0" # Ollama
# LITELLM_PROXY_MODEL_NAME="qwen2.5-coder:32b-instruct-q8_0" # Ollama
# LITELLM_PROXY_MODEL_NAME="gemini-2.0-flash-lite-preview-02-05:free" # OpenRouter
